{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 12 groups from file: GPT_ili_north.log\n",
      "Parsed 12 groups from file: Llama2_ili_north.log\n",
      "Parsed 12 groups from file: GPT_ili_south.log\n",
      "Parsed 12 groups from file: Llama2_ili_cq.log\n",
      "Parsed 12 groups from file: GPT_ili_cq.log\n",
      "Parsed 12 groups from file: GPT_flu_north.log\n",
      "Parsed 6 groups from file: Llama2_positive_rate.log\n",
      "Parsed 6 groups from file: GPT_positive_rate.log\n",
      "Parsed 12 groups from file: Llama2_flu_north.log\n",
      "Parsed 12 groups from file: Llama2_ili_south.log\n",
      "Parsed 12 groups from file: GPT_flu_usa.log\n",
      "Parsed 12 groups from file: Llama2_flu_usa.log\n",
      "Parsed 12 groups from file: Llama2_flu_south.log\n",
      "Parsed 12 groups from file: GPT_flu_south.log\n",
      "Total parsed rows: 156\n",
      "            filename  seq_len  if_inverse  spearmanR  pearsonR     mae  \\\n",
      "0  GPT_ili_north.log      104           0    -0.0149   -0.0226  1.4360   \n",
      "1  GPT_ili_north.log      104           0     0.0012   -0.0044  1.3830   \n",
      "2  GPT_ili_north.log      104           0    -0.0237   -0.0115  1.4281   \n",
      "3  GPT_ili_north.log      104           1     0.9990    1.0000  1.4361   \n",
      "4  GPT_ili_north.log      104           1     0.9990    1.0000  1.3830   \n",
      "\n",
      "      mse      mape     smape  \n",
      "0  4.5289  319.7278  156.7626  \n",
      "1  4.4305  250.6507  158.6637  \n",
      "2  4.5137  298.5390  155.9601  \n",
      "3  4.5298    0.0031    0.0031  \n",
      "4  4.4306    0.0029    0.0029  \n",
      "汇总数据已输出到 summary.xlsx\n"
     ]
    }
   ],
   "source": [
    "## 整理单个文件夹下所有log文件的结果\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# 定义要解析的目录\n",
    "log_dir = '/data_disk/lichx/NeurIPS2023-One-Fits-All/Long-term_Forecasting/Output/Result_no_train'\n",
    "\n",
    "\n",
    "# 定义正则表达式来匹配所需的数据\n",
    "pattern = re.compile(\n",
    "    r'seq_len:\\s*(\\d+)\\s*if_inverse:\\s*(\\d+).*?'\n",
    "    r'spearmanR:\\s*([\\d\\.-]+).*?pearsonR:\\s*([\\d\\.-]+).*?'\n",
    "    r'mae:\\s*([\\d\\.-]+).*?mse:\\s*([\\d\\.-]+).*?mape:\\s*([\\d\\.-]+).*?smape:\\s*([\\d\\.-]+)',\n",
    "    re.DOTALL\n",
    ")\n",
    "\n",
    "# 初始化数据字典\n",
    "data = {\n",
    "    'filename': [],\n",
    "    'seq_len': [],\n",
    "    'if_inverse': [],\n",
    "    'spearmanR': [],\n",
    "    'pearsonR': [],\n",
    "    'mae': [],\n",
    "    'mse': [],\n",
    "    'mape': [],\n",
    "    'smape': []\n",
    "}\n",
    "\n",
    "# 遍历目录中的所有.log文件\n",
    "for filename in os.listdir(log_dir):\n",
    "    if filename.endswith('.log'):\n",
    "        filepath = os.path.join(log_dir, filename)\n",
    "        with open(filepath, 'r') as file:\n",
    "            content = file.read()\n",
    "            matches = pattern.findall(content)\n",
    "            if matches:\n",
    "                for match in matches:\n",
    "                    data['filename'].append(filename)\n",
    "                    data['seq_len'].append(int(match[0]))\n",
    "                    data['if_inverse'].append(int(match[1]))\n",
    "                    data['spearmanR'].append(float(match[2]))\n",
    "                    data['pearsonR'].append(float(match[3]))\n",
    "                    data['mae'].append(float(match[4]))\n",
    "                    data['mse'].append(float(match[5]))\n",
    "                    data['mape'].append(float(match[6]))\n",
    "                    data['smape'].append(float(match[7]))\n",
    "            else:\n",
    "                print(f\"No matches found in file: {filename}\")\n",
    "        print(f\"Parsed {len(matches)} groups from file: {filename}\")\n",
    "\n",
    "# 将数据转换为DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 检查是否正确读取所有数据\n",
    "print(f\"Total parsed rows: {len(df)}\")\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "# 输出到Excel文件\n",
    "output_file = 'summary.xlsx'\n",
    "df.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"汇总数据已输出到 {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 6 groups from file: NorthChinaFlu/Llama2_no_scale_layers_6.log\n",
      "Parsed 6 groups from file: NorthChinaILI/Llama2_no_scale_layers_6.log\n",
      "Parsed 3 groups from file: PositiveRate/Llama2_no_scale_layers_6.log\n",
      "Parsed 6 groups from file: SouthChinaFlu/Llama2_no_scale_layers_6.log\n",
      "Parsed 6 groups from file: SouthChinaILI/Llama2_no_scale_layers_6.log\n",
      "Parsed 6 groups from file: USAFlu/Llama2_no_scale_layers_6.log\n",
      "Parsed 6 groups from file: Weekly/Llama2_no_scale_layers_6.log\n",
      "Total parsed rows: 39\n",
      "      foldername                      filename  seq_len  if_inverse  \\\n",
      "0  NorthChinaFlu  Llama2_no_scale_layers_6.log       52           0   \n",
      "1  NorthChinaFlu  Llama2_no_scale_layers_6.log       52           0   \n",
      "2  NorthChinaFlu  Llama2_no_scale_layers_6.log       52           0   \n",
      "3  NorthChinaFlu  Llama2_no_scale_layers_6.log       52           1   \n",
      "4  NorthChinaFlu  Llama2_no_scale_layers_6.log       52           1   \n",
      "\n",
      "   spearmanR  pearsonR     mae      mse       mape     smape  \n",
      "0     0.1399    0.1356  5.5000  49.0853  2133.4929  151.5692  \n",
      "1     0.1336    0.1434  4.5130  34.0053  1368.1431  146.4125  \n",
      "2     0.2171    0.2356  3.0795  16.3364   768.9301  136.6954  \n",
      "3     0.4983    0.5455  5.5000  49.0853   205.3433   78.9153  \n",
      "4     0.6844    0.7013  4.5130  34.0053   142.2167   68.2490  \n",
      "详细数据已输出到 detailed_summary.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# 定义包含不同路径的列表\n",
    "log_dirs = [\n",
    "    '/data_disk/lichx/NeurIPS2023-One-Fits-All/Long-term_Forecasting/Output/NorthChinaFlu',\n",
    "    '/data_disk/lichx/NeurIPS2023-One-Fits-All/Long-term_Forecasting/Output/NorthChinaILI',\n",
    "    '/data_disk/lichx/NeurIPS2023-One-Fits-All/Long-term_Forecasting/Output/PositiveRate',\n",
    "    '/data_disk/lichx/NeurIPS2023-One-Fits-All/Long-term_Forecasting/Output/SouthChinaFlu',\n",
    "    '/data_disk/lichx/NeurIPS2023-One-Fits-All/Long-term_Forecasting/Output/SouthChinaILI',\n",
    "    '/data_disk/lichx/NeurIPS2023-One-Fits-All/Long-term_Forecasting/Output/USAFlu',\n",
    "    '/data_disk/lichx/NeurIPS2023-One-Fits-All/Long-term_Forecasting/Output/Weekly'\n",
    "]\n",
    "\n",
    "# 定义正则表达式来匹配所需的数据\n",
    "pattern = re.compile(\n",
    "    r'seq_len:\\s*(\\d+)\\s*if_inverse:\\s*(\\d+).*?'\n",
    "    r'spearmanR:\\s*([\\d\\.-]+).*?pearsonR:\\s*([\\d\\.-]+).*?'\n",
    "    r'mae:\\s*([\\d\\.-]+).*?mse:\\s*([\\d\\.-]+).*?mape:\\s*([\\d\\.-]+).*?smape:\\s*([\\d\\.-]+)',\n",
    "    re.DOTALL\n",
    ")\n",
    "\n",
    "# 初始化数据字典\n",
    "data = {\n",
    "    'foldername': [],\n",
    "    'filename': [],\n",
    "    'seq_len': [],\n",
    "    'if_inverse': [],\n",
    "    'spearmanR': [],\n",
    "    'pearsonR': [],\n",
    "    'mae': [],\n",
    "    'mse': [],\n",
    "    'mape': [],\n",
    "    'smape': []\n",
    "}\n",
    "\n",
    "# 遍历每个路径中的所有.log文件\n",
    "for log_dir in log_dirs:\n",
    "    for filename in os.listdir(log_dir):\n",
    "        if filename.endswith('layers_6.log'):\n",
    "            filepath = os.path.join(log_dir, filename)\n",
    "            foldername = os.path.basename(log_dir)\n",
    "            with open(filepath, 'r') as file:\n",
    "                content = file.read()\n",
    "                matches = pattern.findall(content)\n",
    "                if matches:\n",
    "                    for match in matches:\n",
    "                        data['foldername'].append(foldername)\n",
    "                        data['filename'].append(filename)\n",
    "                        data['seq_len'].append(int(match[0]))\n",
    "                        data['if_inverse'].append(int(match[1]))\n",
    "                        data['spearmanR'].append(float(match[2]))\n",
    "                        data['pearsonR'].append(float(match[3]))\n",
    "                        data['mae'].append(float(match[4]))\n",
    "                        data['mse'].append(float(match[5]))\n",
    "                        data['mape'].append(float(match[6]))\n",
    "                        data['smape'].append(float(match[7]))\n",
    "                else:\n",
    "                    print(f\"No matches found in file: {foldername}/{filename}\")\n",
    "            print(f\"Parsed {len(matches)} groups from file: {foldername}/{filename}\")\n",
    "\n",
    "# 将数据转换为DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 检查是否正确读取所有数据\n",
    "print(f\"Total parsed rows: {len(df)}\")\n",
    "print(df.head())\n",
    "\n",
    "# 输出到Excel文件\n",
    "output_file = 'detailed_summary.xlsx'\n",
    "df.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"详细数据已输出到 {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm4ts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
